<!-- Services Section -->
    <section id="call-for-papers">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Call for Papers</h2>
                </div>
            </div>
            <div class="row">
                <div class="col-md-10 text-justify col-md-offset-1">
                    <p>Technology plays a crucial role in people’s lives, influencing several aspects of modern society, such as work, education, politics, and leisure. If software engineering does not strive to be inclusive in all its facets (i.e., education, research, and industry), software products might unintentionally constrain groups of users. The expectation that software is effective in representing the multifaceted characteristics of our society has transcended technical needs and now stands as an ethical obligation for developing algorithms and systems that are both equitable and inclusive. In this context, the concept of software fairness emerges as a crucial non-functional requirement and a quality attribute for software, especially those based on data-driven processes.</p>
                    <p>Software fairness refers to the ethical principle and practice of ensuring that software systems, algorithms, and their outcomes are just, equitable, and unbiased across different groups of people, regardless of their characteristics such as race, gender, ethnicity, or socioeconomic status. In software engineering, fairness typically involves preventing discrimination, promoting inclusivity, and mitigating potential biases in the design, development, deployment, and usage of software systems. Though not entirely new to software development, this concept has only recently gained traction, fueled by the escalating discussions surrounding software engineering for artificial intelligence and ethics in machine learning —a scenario that highlights its essential role in understanding the impact of biased software in modern software engineering practices. However, this debate is still evolving slowly. It seems counter-intuitive, but the area responsible for creating innovative software solutions for billions of users worldwide does not reflect the diversity of the society it serves, e.g., algorithms are racist, technical forums are sexist, and the software industry is not welcoming to underrepresented groups.</p>
                    <p>The International Workshop on Fairness in Software Systems (Fairness’2025) is a unique event bringing together academics, industrial researchers, and practitioners for exchanging experiences, solutions, and new ideas in applying methods, techniques and tools from software analysis, evolution and re-engineering to advance the state of the art in software fairness. The topics of interest include, but are not limited to:</p>
                    <ul>
                        <li><b>Bias in Machine Learning Models:</b> Identifying and mitigating bias in training data; Algorithmic fairness and bias detection techniques; Case studies of bias in deployed systems.</li>
                        <li><b>Fairness in AI and Machine Learning:</b> Definitions and metrics of fairness; Fairness-aware machine learning algorithms; Trade-offs between fairness and other performance metrics.</li>
                        <li><b>Ethical Implications of Software Fairness:</b> Ethical considerations in AI development and deployment; Societal impact of unfair software.</li>
                        <li><b>Transparency and Accountability in Software:</b> Explainable AI and interpretability of machine learning models; Auditing and monitoring AI systems for fairness; Accountability mechanisms for software developers and organizations.</li>
                        <li><b>Data Collection and Preprocessing for Fairness:</b> Techniques for collecting unbiased and representative data; Data preprocessing methods to ensure fairness; Handling missing data and data augmentation for fairness.</li>
                        <li><b>Fairness in Human-Computer Interaction (HCI):</b> Designing user interfaces that promote fairness; User perception and trust in fair AI systems; Inclusive design practices and accessibility considerations.</li>
                        <li><b>Mitigating Fairness Issues in Software Development Lifecycle:</b> Integrating fairness checks in the software development process; Tools and frameworks for developing fair software; Best practices for collaborative and inclusive development teams.</li>
                        <li><b>Evaluating and Benchmarking Fairness:</b> Standard datasets and benchmarks for fairness evaluation; Comparative studies of fairness metrics and algorithms; Real-world deployment and evaluation of fairness interventions.</li>
                        <li><b>Software Fairness Debt:</b> Definition and conceptualization of software fairness debt; Impact of fairness debt on long-term system performance and trust; Identifying and Measuring Fairness Debt; Managing and Mitigating Fairness Debt; Economic and Organizational Impact of Fairness Debt; Technical Approaches to Fairness Debt Remediation.</li>
                    </ul>
                    <p>We welcome articles presenting novel and strong contributions to deal with software fairness, including (i) state-of-the-art methods, models, and tools (with evidence of use and study of practical impact) or bridging the gap between practice and research, (ii) empirical studies in the field, addressing one or many human, technical, social, and economic issues of software fairness through qualitative and/or quantitative analyses, and (iii) industrial experiences, including good practices and lessons learned from managing software fairness in specific contexts or domains.</p>
                </div>
            </div>
        </div>
    </section>